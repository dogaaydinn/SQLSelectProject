# CUDA Analytics Service

GPU-accelerated salary analytics microservice using NVIDIA CUDA, cuPy, and cuDF.

## ğŸš€ Overview

This service provides **10-50x performance improvements** for salary analytics operations by leveraging GPU acceleration through CUDA. It automatically falls back to CPU processing when GPU is unavailable, ensuring reliability across environments.

### Key Features

- **GPU-Accelerated Analytics**: CUDA kernels for parallel computation
- **cuPy Integration**: NumPy-compatible GPU arrays for fast numerical operations
- **cuDF Support**: GPU DataFrames for efficient data manipulation
- **Automatic CPU Fallback**: Seamless operation without GPU hardware
- **Real-time Statistics**: Mean, median, std, percentiles, skewness, kurtosis
- **Department Aggregation**: Group-by operations optimized for GPU
- **Outlier Detection**: IQR and Z-score methods with parallel processing
- **Growth Rate Analysis**: Year-over-year salary growth calculations
- **Performance Benchmarking**: Built-in GPU vs CPU comparison tools

## ğŸ“Š Performance

Benchmark results on NVIDIA Tesla T4 (16GB):

| Operation | Data Size | GPU Time | CPU Time | Speedup |
|-----------|-----------|----------|----------|---------|
| Statistics | 100K | 12ms | 245ms | **20.4x** |
| Dept Aggregation | 100K | 18ms | 520ms | **28.9x** |
| Outlier Detection | 100K | 15ms | 380ms | **25.3x** |
| Growth Rate | 100K | 8ms | 195ms | **24.4x** |

**Average Speedup: 24.8x**

## ğŸ› ï¸ Tech Stack

- **FastAPI**: Async web framework (Python 3.11)
- **CUDA 12.2**: NVIDIA parallel computing platform
- **cuPy 12.3**: GPU-accelerated NumPy
- **cuDF 23.10**: RAPIDS GPU DataFrame library
- **Numba 0.58**: JIT compiler for CUDA kernels
- **PostgreSQL 16**: Read-only database access
- **Redis 7**: Result caching
- **Prometheus**: Metrics collection

## ğŸ“¦ Installation

### Prerequisites

- NVIDIA GPU with CUDA Compute Capability 6.0+ (Pascal or newer)
- CUDA Toolkit 12.x installed
- Docker with NVIDIA Container Toolkit
- 8GB+ GPU memory recommended

### Local Development

```bash
# Clone repository
cd services/analytics-cuda

# Create virtual environment
python3.11 -m venv venv
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt

# Set environment variables
export DATABASE_URL="postgresql+asyncpg://user:pass@localhost:5432/employees_db"
export REDIS_URL="redis://localhost:6379/0"
export USE_GPU=true
export CUDA_DEVICE=0

# Run service
python -m uvicorn app.main:app --host 0.0.0.0 --port 8001
```

### Docker Deployment

```bash
# Build image
docker build -t analytics-cuda:latest .

# Run with GPU support
docker run --gpus all \
  -p 8001:8001 \
  -e DATABASE_URL="postgresql+asyncpg://user:pass@db:5432/employees_db" \
  -e USE_GPU=true \
  analytics-cuda:latest
```

### Docker Compose

```yaml
services:
  analytics-cuda:
    build: ./services/analytics-cuda
    ports:
      - "8001:8001"
    environment:
      - DATABASE_URL=postgresql+asyncpg://postgres:postgres@db:5432/employees_db
      - REDIS_URL=redis://redis:6379/0
      - USE_GPU=true
      - CUDA_DEVICE=0
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
```

## ğŸ”Œ API Endpoints

### Analytics Endpoints

#### GET `/api/v1/analytics/summary`
Get service capabilities and GPU status.

**Response**:
```json
{
  "total_employees": 300024,
  "total_departments": 9,
  "gpu_accelerated": true,
  "available_operations": ["salary_statistics", "department_statistics", ...],
  "performance_metrics": {
    "mode": "GPU",
    "device_name": "Tesla T4",
    "total_memory_gb": 15.89,
    "free_memory_gb": 12.45,
    "memory_utilization": 21.64
  }
}
```

#### GET `/api/v1/analytics/salary/statistics`
Compute comprehensive salary statistics.

**Query Parameters**:
- `current_only` (bool): Only current salaries (default: true)
- `department_id` (str): Filter by department

**Response**:
```json
{
  "count": 300024,
  "mean": 63810.74,
  "median": 60117.00,
  "std": 16904.25,
  "min": 38623.00,
  "max": 158220.00,
  "q25": 50493.50,
  "q75": 75654.00,
  "variance": 285753593.12,
  "skewness": 0.72,
  "kurtosis": 0.24
}
```

#### GET `/api/v1/analytics/salary/by-department`
Group salary statistics by department.

**Response**:
```json
[
  {
    "dept_id": 1,
    "dept_name": "Marketing",
    "count": 14842,
    "mean": 71420.32,
    "median": 68500.00,
    "std": 17234.51,
    "min": 39000.00,
    "max": 145000.00
  },
  ...
]
```

#### POST `/api/v1/analytics/salary/outliers`
Detect salary outliers using IQR or Z-score method.

**Request Body**:
```json
{
  "method": "iqr",
  "department_id": "d001"
}
```

**Response**:
```json
{
  "outlier_count": 142,
  "method": "iqr",
  "outliers": [
    {
      "emp_no": 10001,
      "first_name": "John",
      "last_name": "Doe",
      "salary": 158220.00
    },
    ...
  ]
}
```

#### POST `/api/v1/analytics/salary/growth-rate`
Analyze salary growth rates between two dates.

**Request Body**:
```json
{
  "start_date": "2020-01-01",
  "end_date": "2023-01-01",
  "department_id": "d005"
}
```

**Response**:
```json
{
  "average_growth_rate": 8.45,
  "median_growth_rate": 7.20,
  "growth_by_employee": [
    {
      "emp_no": 10001,
      "first_name": "John",
      "last_name": "Doe",
      "start_salary": 60000.00,
      "end_salary": 68500.00,
      "growth_rate": 14.17
    },
    ...
  ]
}
```

### Benchmarking Endpoints

#### GET `/api/v1/benchmark/statistics`
Benchmark salary statistics computation (GPU vs CPU).

**Query Parameters**:
- `data_size` (int): Number of records (1000-1000000)

**Response**:
```json
{
  "operation": "salary_statistics",
  "data_size": 100000,
  "gpu_available": true,
  "gpu_time_ms": 12.45,
  "cpu_time_ms": 245.82,
  "speedup": 19.74
}
```

#### GET `/api/v1/benchmark/comprehensive`
Run comprehensive benchmark suite across all operations.

**Response**:
```json
{
  "data_size": 100000,
  "gpu_available": true,
  "average_speedup": 24.78,
  "operations": {
    "statistics": {...},
    "aggregation": {...},
    "outlier_detection": {...},
    "growth_rate": {...}
  }
}
```

### Health & Metrics

#### GET `/health`
Health check endpoint.

#### GET `/metrics`
Prometheus metrics endpoint.

Exposed metrics:
- `analytics_gpu_memory_used_bytes`: GPU memory usage
- `analytics_gpu_memory_total_bytes`: Total GPU memory
- `analytics_operations_total`: Counter of analytics operations
- `analytics_operation_duration_seconds`: Histogram of operation duration
- `analytics_gpu_utilization`: GPU utilization percentage

## ğŸ”§ Configuration

Environment variables:

```bash
# Application
APP_NAME="CUDA Analytics Service"
DEBUG=false

# Server
HOST=0.0.0.0
PORT=8001
WORKERS=4

# Database (read-only)
DATABASE_URL=postgresql+asyncpg://user:pass@host:5432/db
DB_POOL_SIZE=10

# Redis
REDIS_URL=redis://localhost:6379/0
CACHE_TTL=300

# CUDA/GPU
CUDA_DEVICE=0  # GPU device ID
USE_GPU=true  # Enable GPU acceleration
GPU_MEMORY_FRACTION=0.8  # Use 80% of GPU memory

# cuDF
CUDF_SPILL=true  # Enable spilling to host memory
CUDF_SPILL_DEVICE_LIMIT=8GB

# Performance
BATCH_SIZE=10000  # Batch size for GPU operations
MAX_WORKERS=4  # CPU parallelization

# Monitoring
ENABLE_METRICS=true
METRICS_PORT=9090
LOG_LEVEL=INFO
```

## ğŸ§ª Testing

```bash
# Run unit tests
pytest tests/unit

# Run integration tests
pytest tests/integration

# Run with coverage
pytest --cov=app tests/
```

## ğŸ“ˆ Monitoring

The service exposes Prometheus metrics at `/metrics`:

```bash
# Scrape metrics
curl http://localhost:8001/metrics

# Example metrics
analytics_operations_total{operation="statistics"} 1247
analytics_operation_duration_seconds_bucket{operation="statistics",le="0.01"} 856
analytics_gpu_memory_used_bytes{device="0"} 3.4e+09
analytics_gpu_utilization{device="0"} 42.5
```

## ğŸ” Debugging

### GPU Not Detected

```bash
# Check CUDA availability
python -c "import cupy as cp; print(cp.cuda.runtime.getDeviceCount())"

# Check NVIDIA drivers
nvidia-smi

# Verify CUDA toolkit
nvcc --version
```

### Force CPU Mode

```bash
# Disable GPU acceleration
export USE_GPU=false
python -m uvicorn app.main:app
```

### Memory Issues

```bash
# Reduce GPU memory fraction
export GPU_MEMORY_FRACTION=0.5

# Enable cuDF spilling
export CUDF_SPILL=true
export CUDF_SPILL_DEVICE_LIMIT=4GB

# Reduce batch size
export BATCH_SIZE=5000
```

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  FastAPI Application Layer          â”‚
â”‚  (endpoints, validation, routing)   â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  GPU Analytics Service               â”‚
â”‚  (business logic, caching)           â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  GPU Computing Layer                 â”‚
â”‚  â”œâ”€â”€ cuPy (NumPy-compatible)        â”‚
â”‚  â”œâ”€â”€ cuDF (pandas-compatible)       â”‚
â”‚  â””â”€â”€ Custom CUDA Kernels            â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚  CUDA Runtime & Drivers              â”‚
â”‚  (NVIDIA GPU hardware)               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ¤ Integration with Main API

The CUDA analytics service is designed to work alongside the main FastAPI service:

```python
# In main API service
import httpx

async def get_advanced_statistics(department_id: str):
    """Call CUDA analytics service for GPU-accelerated stats."""
    async with httpx.AsyncClient() as client:
        response = await client.get(
            f"http://analytics-cuda:8001/api/v1/analytics/salary/statistics",
            params={"department_id": department_id}
        )
        return response.json()
```

## ğŸ“ License

Part of the SQLSelectProject enterprise employee management system.

## ğŸ‘¥ Contributors

Implemented as part of enterprise-grade architecture improvements following Silicon Valley Senior Software Engineer and NVIDIA Developer standards.

---

**Note**: This service requires NVIDIA GPU hardware for GPU acceleration. It will automatically fall back to CPU mode if GPU is unavailable, ensuring reliability across all environments.
